\documentclass[10pt,landscape, a4paper]{article}
\usepackage[legalpaper, landscape, right=.2in, top=.25in, bottom=.5in, left=.2in]{geometry}
\usepackage{multicol}
\usepackage{amsfonts}
\usepackage{amsmath,amsthm}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{tcolorbox}
\setlength{\columnseprule}{1pt}
\setcounter{section}{1}
\tcbuselibrary{listings,breakable}


\newcommand{\custombox}[3]{\begin{tcolorbox}[left=0mm,right=0mm,bottom=0mm,top=0mm,title = \textbf{#1}, colback=#2!10!white, colframe = #2!70!white, coltitle=white, breakable]
    #3
    \end{tcolorbox}}

\newcommand{\theorem}[2]{\custombox{Theorem #1}{violet}{#2}}
\newcommand{\definition}[2]{\custombox{Definition #1}{red}{#2}}
\newcommand{\prop}[2]{\custombox{Proposition #1}{black!50!orange!30!yellow}{#2}}
\newcommand{\other}[2]{\custombox{#1}{green!60!black}{#2}}
\newcommand{\lemma}[2]{\custombox{Lemma #1}{blue!60!black}{#2}}
\newcommand{\corollary}[2]{\custombox{Corollary #1}{orange}{#2}}


\newcommand{\R}{\mathbb{R}}
\newcommand{\Rn}{\R^n}
\newcommand{\Rm}{\R^m}


\begin{document}
\begin{multicols*}{3}
    \begin{center}
        \Large{\textbf{Analysis II HS21}} \\
        \small{by plaffranchi}
    \end{center}
    \section{ODE (ordinary differential equation)}
    \theorem{2.1.6}{Let $F: \mathbb{R}^{2} \rightarrow \mathbb{R}$ be differentiable. Let $x_{0} \in \mathbb{R}$ and $y_{0} \in \mathbb{R}^{2}$. Then the ODE
    $ y^{\prime}=F(x, y) $ has a unique solution $f$ defined on a "largest" open interval I containing $x_{0}$ such that $f\left(x_{0}\right)=y_{0} .$}
    \definition{2.2.1}{Let $I \subset \mathbb{R}$ be an open interval and $k \in \mathbb{N}_0$. An homogeneous linear ODE of order $k$ on $I$ is of the form
    $
        y^{(k)}+a_{k-1} y^{(k-1)}+\cdots+a_{1} y^{\prime}+a_{0} y=0
    $
    where the coefficients $a_{0}, \ldots, a_{k-1}$ are complex-valued functions on $I$, and the unknown is a function $I \to \mathbb{C}$ that is $k$-times differentiable on $I$.
    An equation of the form
    $
        y^{(k)}+a_{k-1} y^{(k-1)}+\cdots+a_{1} y^{\prime}+a_{0} y=b,
    $
    where $b: I \rightarrow \mathbb{C}$ is another function, is called an inhomogeneous linear ODE.}
    \other{Recognize an ODE}{\begin{enumerate}
            \item no coefficients before the highest derivative
            \item all coefficients are continuous
            \item no products of $y$ or their derivatives
            \item no powers of $y$ or their derivatives
            \item no functions depending on $y$ or their derivatives
        \end{enumerate}}

    % Theorem 2.2.3?


    \prop{2.3.1}{Any solution of $y'+ay=0$ is of the form $f(x)=z\exp(-A(x))$ where $A$ is a primitive of $a$. The unique solution with $f(x_0)=y_0$ is $f(x)= y_0\exp(A(x_0)-A(x))$.}


    \other{Solving inhomogeneous equations}{\textbf{Case 1:} Make a guess. For example $y'=y+x^2$ guess $f(x) = ax^2+bx+c$, and solve the equation.\\
        \textbf{Case 2:} Use the variation of the constant. Assume $f_p=z(x)\exp(-A(x))$ for $z: I\to \mathbb{C}$. Then $z'(x) = b(x)\exp(A(x)) \implies k(x) = \int b(x)\exp(A(x))dx$.}


    \definition{Linear differential equations with constant coefficients}{Let $k \in \mathbb{N}_0$, $a_0,...,a_{k-1} \in \mathbb{C}$ fixed and $b$ a general continuous function, then $y^{(k)}+a_{k-1} y^{(k-1)}+\cdots+a_{1} y^{\prime}+a_{0} y=b$ is such equation.}


    \other{Solution of hom. diff. eq. with constant coefficients}{Look for solutions of the form $f(x)=e^{\alpha x}$ for $\alpha \in \mathbb{C}$. Then we have $f^{(j)}(x)=\alpha^{j} e^{\alpha x}$ for all $j \geqslant 0$ and for all $x$, which means that
    \begin{align*}
          & f^{(k)}(x)+a_{k-1} f^{(k-1)}(x)+\cdots+a_{1} f^{\prime}(x)+a_{0} f(x)                \\
        = & e^{\alpha x}\left(\alpha^{k}+a_{k-1} \alpha^{k-1}+\cdots+a_{1} \alpha+a_{0}\right) .
    \end{align*}
    This translates into finding the zeros of the characteristic polynomial:
    \begin{align*}
        P(X)= & X^{k}+a_{k-1} X^{k}+\cdots+a_{1} X+a_{0}                      \\
        =     & \left(X-\alpha_{1}\right) \cdots\left(X-\alpha_{k}\right) = 0
    \end{align*} }


    \other{Imaginary roots}{If a root is not real i.e. $\alpha = \beta + i\gamma$, the solution $f(x)=e^{\alpha x}$ does not take real values, but $\overline{\alpha} = \beta - i\gamma$ is also a root, hence we can write $\widetilde{f}_{1}(x)=e^{\beta x} \cos (\gamma x), \quad \widetilde{f}_{2}(x)=e^{\beta x} \sin (\gamma x)$ instead of $f_{1}(x)=e^{\alpha x}, \quad f_{2}(x)=e^{\bar{\alpha} x}$}


    \other{Multiple roots}{\textbf{Case 1: no multiple roots.} Any solution of the equation is of the form $f(x) = z_1e^{a_1x}+\cdots +z_ke^{a_kx}$.\\
    \textbf{Case 2: multiple roots.}  Suppose that $\alpha$ is a multiple root of order $j$ with $2 \leqslant j \leqslant k$. Then the $k$ functions
    $
        f_{\alpha, 0}(x)=e^{\alpha x}, \quad f_{\alpha, 1}(x)=x e^{\alpha x}, \quad \cdots, \quad f_{\alpha, j-1}(x)=x^{j-1} e^{\alpha x}
    $
    are linearly independent solutions. Taking the union of the functions $f_{\alpha, j}$ for all roots of $P$, each with its multiplicity, gives a basis of the space of solutions.}

    \section{Differential calculus in $\mathbb{R}^n$}


    \definition{3.2.1.}{Let $\left(x_{k}\right)_{k \in \mathbb{N}}$ where $x_{k} \in \mathbb{R}^{n}$. Write
    $
        x_{k}=\left(x_{k, 1}, \ldots, x_{k, n}\right) .
    $
    Let $y=\left(y_{1}, \ldots, y_{n}\right) \in \mathbb{R}^{n}$. The sequence $\left(x_{k}\right)$ converges to ($\to$) $y$ as $k \rightarrow+\infty$ if  $\forall \varepsilon>0$, if $\exists N \geqslant 1$ such that  $\forall n \geqslant N$, we have
    $
        \left\|x_{k}-y\right\|<\varepsilon \text {. }
    $}

    \lemma{3.2.2.}{
    $\left(x_{k}\right) \to y$ as $k \rightarrow+\infty$ $\iff$ either:
    (1) $\forall i, 1 \leqslant i \leqslant n$, the sequence of real numbers $\left(x_{k, i}\right) \to y_{i}$.
    (2) The sequence of real numbers $\left\|x_{k}-y\right\|\to 0$ as $k \rightarrow+\infty$.}


    \definition{3.2.3.}{ Let $X \subset \mathbb{R}^{n}$ and $f: X \rightarrow \mathbb{R}^{m}$. (1) Let $x_{0} \in X$. $f$ is continuous at $x_{0}$ if $\forall \varepsilon>0\ \exists \delta>0$ s.t. $\left\|x-x_{0}\right\|<\delta \implies
        \left\|f(x)-f\left(x_{0}\right)\right\|<\varepsilon$, $\forall x \in X$. (2) $f$ is continuous on $X$ if it is continuous at $x_{0}$ $\forall x_{0} \in X$.}


    \prop{3.2.4.}{Let $X \subset \mathbb{R}^{n}$ and $f: X \rightarrow \mathbb{R}^{m}$. Let $x_{0} \in X$. The function $f$ is continuous at $x_{0} \iff \forall \left(x_{k}\right)_{k} \geqslant 1$ in $X$ s.t. $x_{k} \rightarrow x_{0}$ as $k \rightarrow+\infty$, the sequence $\left(f\left(x_{k}\right)\right)_{k} \geqslant 1$ in $\mathbb{R}^{m}$ converges to $f(x)$.}


    \definition{3.2.5.}{Let $X \subset \mathbb{R}^{n}$ and $f: X \rightarrow \mathbb{R}^{m}$. Let $x_{0} \in X$ and $y \in \mathbb{R}^{m}$. We say that $f$ has the limit $y$ as $x \rightarrow x_{0}$ with $x \neq x_{0}$ if for every $\varepsilon>0$, there exists $\delta>0$, s.t.  $\forall x \in X, x \neq x_{0}$, s.t. $\left\|x-x_{0}\right\|<\delta$, we have $\|f(x)-y\|<\varepsilon$. We then write
    $
        \lim _{x \rightarrow x_{0} \atop x \neq x_{0}} f(x)=y
    $.}


    \prop{3.2.7.}{Let $X \subset \mathbb{R}^{n}$ and $f: X \rightarrow \mathbb{R}^{m} .$ Let $x_{0} \in X$ and $y \in \mathbb{R}^{m} .$ We have
        $
            \lim _{x \rightarrow x_{0} \atop x \neq x_{0}} f(x)=y \iff
        $
        $\forall\left(x_{k}\right) \in X$ s.t. $x_{k} \rightarrow x$ as $k \rightarrow+\infty$, and $x_{k} \neq x_{0}$, the sequence $\left(f\left(x_{k}\right)\right)$ in $\mathbb{R}^{m}$ converges to $y$.}


    \prop{3.2.9.}{Let $X \subset \mathbb{R}^{n}, Y \subset \mathbb{R}^{m}$ and $p \geqslant 1$ an integer. Let $f: X \rightarrow Y$ and $g: Y \rightarrow \mathbb{R}^{p}$ be continuous functions. Then the composite $g \circ f$ is continuous.}

    \definition{3.2.11.}{
       (1) A subset $X \subset \mathbb{R}^{n}$ is bounded if the set of $\|x\|$ for $x \in X$ is bounded in $\mathbb{R}$.
(2) A subset $X \subset \mathbb{R}^{n}$ is closed if for every sequence $\left(x_{k}\right)$ in $X$ that converges in $\mathbb{R}^{n}$ to some vector $y \in \mathbb{R}^{n}$, we have $y \in X$.
(3) A subset $X \subset \mathbb{R}^{n}$ is compact if it is bounded and closed.
    }

    \prop{3.2.13.}{Let $g:\Rn \to \Rm$ be a continuous map. For any closed set $Y\subset \Rm$, $f^{-1}(Y) = {x\in\Rn : f(x)\in Y} \subset \Rn$ is closed.}

    \theorem{3.2.15.}{Let $X\subset \Rn$ be a non-empty compact set and $f:X\to\R$ a continuous function. Then $f$ is bounded and achieves its max and min. I.e. $\exists x_+,x_-\in X$ s.t. $f(x_+)=\sup_{x\in X}f(x)$, $f(x_-)=\inf_{x\in X}f(x)$.}

    \definition{3.3.1.}{A subset $X \subset \Rn$ is open if, for any $x=\left(x_{1}, \ldots, x_{n}\right) \in X$, there exists $\delta>0$ such that the set
$$
\left\{y=\left(y_{1}, \ldots, y_{n}\right) \in \Rn:\left|x_{i}-y_{i}\right|<\delta \text { for all } i\right\}
$$
is contained in $X$.
In other words: any point of $\Rn$ obtained by changing any coordinate of $x$ by at most $\delta$ is still in $X$.}

\prop{3.3.2.}{A set $X \subset \Rn$ is open if and only if the complement
$
Y=\left\{x \in \Rn: x \notin X\right\}
$
is closed.}

\corollary{3.3.3.}{If $f: \Rn \rightarrow \Rm$ is continuous and $Y \subset \Rm$ is open, then $f^{-1}(Y)$ is open in $\Rn$.}

\definition{3.3.5}{Let $X \subset \Rn$ be an open set. Let $f: X \rightarrow \Rm$ be a function. Let $1 \leqslant i \leqslant n$. We say that $f$ has a partial derivative on $X$ with respect to the $i$-th variable, or coordinate, if for all $x_{0}=\left(x_{0,1}, \ldots, x_{0, n}\right) \in X$, the function defined by
$$
g(t)=f\left(x_{0,1}, \ldots, x_{0, i-1}, t, x_{0, i+1}, \ldots, x_{0, n}\right)
$$
on the set
$
I=\left\{t \in \R:\left(x_{0,1}, \ldots, x_{0, i-1}, t, x_{0, i+1}, \ldots, x_{0, n}\right) \in X\right\}
$
is differentiable at $t=x_{0, i}$. Its derivative $g^{\prime}\left(x_{0, i}\right)$ at $x_{0, i}$ is denoted
$$
\frac{\partial f}{\partial x_{i}}\left(x_{0}\right), \quad \partial_{x_{i}} f\left(x_{0}\right), \quad \partial_{i} f\left(x_{0}\right)
$$}

\prop{3.3.7.}{Consider $X \subset \mathbf{R}^{n}$ open and $f, g$ functions from $X$ to $\mathbf{R}^{m}$. Let $1 \leqslant i \leqslant n$.
(1) If $f$ and $g$ have partial derivatives with respect to the $i$-th coordinate on $X$, then $f+g$ also does, and
$$
\partial_{x_{i}}(f+g)=\partial_{x_{i}}(f)+\partial_{x_{i}}(g) .
$$
(2) If $m=1$, and if $f$ and $g$ have partial derivatives with respect to the $i$-th coordinate on $X$, then $f g$ also does and
$$
\partial_{x_{i}}(f g)=\partial_{x_{i}}(f) g+f \partial_{x_{i}}(g) .
$$
Furthermore, if $g(x) \neq 0$ for all $x \in X$, then $f / g$ has a partial derivative with respect to the $i$-th coordinate on $X$, with
$$
\partial_{x_{i}}(f / g)=\left(\partial_{x_{i}}(f) g-f \partial_{x_{i}}(g)\right) / g^{2} .
$$}

\definition{3.3.9.}{Let $X \subset \mathbf{R}^{n}$ open and $f: X \rightarrow \mathbf{R}^{m}$ a function with partial derivatives on $X$. Write
$$
f(x)=\left(f_{1}(x), \ldots, f_{m}(x)\right) .
$$
For any $x \in X$, the matrix
$$
J_{f}(x)=\left(\partial_{x_{j}} f_{i}(x)\right)_{1 \leqslant i \leqslant m \atop 1 \leqslant j \leqslant n}
$$
with $m$ rows and $n$ columns is called the Jacobi matrix of $f$ at $x$.}
\end{multicols*}
\end{document}